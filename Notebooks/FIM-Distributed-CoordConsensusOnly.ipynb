{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook runs simulations for our distributed algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also, we only consider fixed-topology networks in the experiments below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "from matplotlib import style\n",
    "from functools import partial\n",
    "\n",
    "from utils.dLdp import analytic_dLdp,analytic_dhdz,analytic_dhdq,analytic_FIM\n",
    "from utils.ConsensusEKF import ConsensusEKF\n",
    "\n",
    "import time\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circulant(i,q,p,prev,post,undirected=False):\n",
    "    \"\"\"\n",
    "        Generate a circulant graph with len(p) nodes, node i connected with [i-prev:i+post],i-prev and i+post included but self-loop eliminated.\n",
    "    \"\"\"\n",
    "    n = len(p)\n",
    "    G = nx.DiGraph()\n",
    "    edges = [(j%n,i) for i in range(n) for j in range(i-prev,i+post+1)]\n",
    "    G.add_edges_from(edges)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    if undirected:\n",
    "        G = G.to_undirected()\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_meas_func(C1,C0,k,b,dist):\n",
    "    return k*(dist-C1)**b+C0\n",
    "\n",
    "def joint_meas_func(C1s,C0s,ks,bs,x,ps):\n",
    "\n",
    "    # Casting for the compatibility of jax.numpy\n",
    "\n",
    "    C1=np.array(C1s)\n",
    "    C0=np.array(C0s)\n",
    "    k=np.array(ks)\n",
    "    b=np.array(bs)\n",
    "    p=np.array(ps)\n",
    "\n",
    "    # Keep in mind that x is a vector of [q,q'], thus only the first half of components are observable.    \n",
    "    dists=np.linalg.norm(x[:len(x)//2]-p,axis=1)\n",
    "\n",
    "    return single_meas_func(C1,C0,k,b,dists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(q,N_trails,N_sen,N_iter,consensus_est=False,coordinate=False,version='v1',FIM_cons_iter=10):\n",
    "    '''Experiment Parameters'''\n",
    "     # Number of sensors.\n",
    "    \n",
    "    p_0 = np.random.rand(N_sen,2)\n",
    "#     qhat_0 = (np.random.rand(N_sen,2))*3\n",
    "#     qhat_0 = np.array([])\n",
    "\n",
    "    comm_network_generator=lambda i,q,p:circulant(i,q,p,prev=1,post=0,undirected=True)\n",
    "    \n",
    "    C_gain=0.0\n",
    "\n",
    "    # Set up virtual sensors\n",
    "    C1=-0.3 # Setting C1 as a negative number mitigates the blowing-up effect when the sensors are close to the source.\n",
    "    C0=0\n",
    "    k=1\n",
    "    b=-2\n",
    "    noise_std = 0.01\n",
    "    minimum_sensing_reading=1e-5\n",
    "\n",
    "    # The communication network and consensus weight matrix.\n",
    "    G = comm_network_generator(0,q,p_0)\n",
    "    A = np.array(nx.adj_matrix(G).todense().astype(float))\n",
    "    A +=np.eye(len(A))\n",
    "\n",
    "    W = A/np.sum(A,axis=1) # The weight matrix required by parallel two-pass algorithm.\n",
    "\n",
    "    # The step size of each sensor\n",
    "    max_linear_speed=0.1\n",
    "\n",
    "    # Terminal condition\n",
    "    contact_radius = 0.1\n",
    "\n",
    "\n",
    "    t=time.time()\n",
    "    data={'p':[],'qhat':[],'q':[]}\n",
    "\n",
    "    for _ in range(N_trails):\n",
    "\n",
    "        '''Initialize Key Data Structures'''\n",
    "        p_0 = np.random.rand(N_sen,2)\n",
    "#         qhat_0 = (np.random.rand(N_sen,2)-0.5)*3\n",
    "        qhat_0 = (np.random.rand(N_sen,2))*3\n",
    "\n",
    "\n",
    "        p = np.array(p_0) # Sensor Positins\n",
    "        qhat = np.array(qhat_0)\n",
    "\n",
    "        def F_single(dh,qhat,ps):\n",
    "            A = dh(qhat,ps)\n",
    "            return A.T.dot(A)\n",
    "\n",
    "        def joint_F_single(qhat,ps): # Verified to be correct.\n",
    "            # The vectorized version of F_single.\n",
    "            # The output shape is (N_sensor, q_dim, q_dim).\n",
    "            # Where output[i]=F_single(dh,qhat,ps[i])\n",
    "            A = analytic_dhdq(qhat,ps,C1s=C1,C0s=C0,ks=k,bs=b)\n",
    "            return A[:,np.newaxis,:]*A[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "        # The list of single-term partial FIM's.\n",
    "        F_0 = joint_F_single(qhat,p)\n",
    "        F = np.array(F_0)\n",
    "\n",
    "        # The list local estimate of global FIM.\n",
    "        if version=='v1':\n",
    "            F_est = F+1e-8*np.eye(2) # Adding a small I to ensure invertibility\n",
    "        elif version=='v3':\n",
    "            local_FIM = np.zeros(F.shape)\n",
    "            for i in G.nodes():\n",
    "                N_i = [i]+list(G[i]) \n",
    "                local_FIM[i,:,:]=analytic_FIM(qhat[N_i,:],p[N_i],C1,C0,k,b)\n",
    "            F_est = local_FIM # v3: initialize F_est to be local FIMs.\n",
    "\n",
    "        # The Consensus EKFs\n",
    "        estimators = [ConsensusEKF(q_0,C_gain=C_gain) for q_0 in qhat_0]\n",
    "\n",
    "        # The initialization of local measurement functions and the derivative functions. \n",
    "        # This is not very pretty. But is required by Consensus EKF.\n",
    "        hs = []\n",
    "        dhdzs = []\n",
    "        dhdqs = []\n",
    "        C1s=C1*np.ones(N_sen)\n",
    "        C0s = C0*np.ones(N_sen)\n",
    "        ks = k * np.ones(N_sen)\n",
    "        bs = b*np.ones(N_sen)\n",
    "\n",
    "        d = np.zeros(N_sen)\n",
    "        for i in G.nodes():  \n",
    "            N_i = [i]+list(G[i])     \n",
    "            C1s_i=C1s[N_i]\n",
    "            C0s_i = C0s[N_i]\n",
    "            ks_i = ks[N_i]\n",
    "            bs_i = bs[N_i]\n",
    "            hs.append(partial(joint_meas_func,C1s_i,C0s_i,ks_i,bs_i))# Freeze the coefficients, the signature becomes h(z,ps))\n",
    "            dhdzs.append(partial(analytic_dhdz,C1s=C1s_i,C0s=C0s_i,ks=ks_i,bs=bs_i))\n",
    "            dhdqs.append(partial(analytic_dhdq,C1s=C1s_i,C0s=C0s_i,ks=ks_i,bs=bs_i))\n",
    "            d[i]=len(N_i)\n",
    "\n",
    "        # Variables for parallel two-pass algorithm.\n",
    "        inv_d = 1/d\n",
    "        w_F_est = F_est*inv_d[:,np.newaxis,np.newaxis]\n",
    "\n",
    "        '''Main Loop'''\n",
    "\n",
    "        p_history = []\n",
    "        qhat_history = []\n",
    "        q_history = []\n",
    "        for _ in range(N_iter):\n",
    "#             if np.min(np.linalg.norm(p-q,axis=1))>contact_radius:#Move and estimate only when not touching the source.\n",
    "            # Measure\n",
    "            r = np.linalg.norm(q-p,axis=1)\n",
    "            y = k* ((r-C1)**b)+C0 + np.random.randn(N_sen)*noise_std\n",
    "            y[y<=0]=minimum_sensing_reading # We don't want y to be zero or negative.\n",
    "\n",
    "\n",
    "            # Estimate\n",
    "            zhats = np.array([est.z for est in estimators])\n",
    "            new_qhat = np.zeros(qhat.shape)\n",
    "            local_FIM = np.zeros(F_est.shape)\n",
    "            for i in G.nodes():\n",
    "                N_i = [i]+list(G[i]) \n",
    "                # Estimate\n",
    "                if consensus_est:\n",
    "                    inv_d_neighbor=inv_d[N_i]\n",
    "                else:\n",
    "                    inv_d_neighbor=None\n",
    "                new_qhat[i,:]=estimators[i].update_and_estimate_loc(hs[i],dhdzs[i],y[N_i],p[N_i],zhats[N_i],consensus_weights=inv_d_neighbor)\n",
    "                if not coordinate:\n",
    "                    local_FIM[i,:,:]=analytic_FIM(qhat[N_i,:],p[N_i],C1,C0,k,b)\n",
    "\n",
    "            qhat=new_qhat\n",
    "\n",
    "            # Partial FIM Calculation and FIM consensus\n",
    "            for _ in range(FIM_cons_iter):\n",
    "                new_F = joint_F_single(qhat,p)\n",
    "                dF = new_F-F\n",
    "                F=new_F\n",
    "\n",
    "                # FIM Consensus using parallel two-pass algorithm\n",
    "                inv_d = W.dot(inv_d)\n",
    "                w_F_est = (w_F_est.T.dot(W)).T + dF*inv_d[:,np.newaxis,np.newaxis]\n",
    "                F_est = w_F_est/inv_d[:,np.newaxis,np.newaxis]   \n",
    "\n",
    "            # Gradient update\n",
    "            FIM_cand= F_est if coordinate else local_FIM\n",
    "            for i in range(N_sen):\n",
    "                dp=analytic_dLdp(qhat[i:i+1],p[i:i+1],C1,C0,k,b,FIM=FIM_cand[i])\n",
    "\n",
    "                p[i:i+1]-=max_linear_speed*dp/np.linalg.norm(dp)\n",
    "\n",
    "            # Record data\n",
    "            p_history.append(np.array(p))\n",
    "            qhat_history.append(np.array(qhat))\n",
    "            q_history.append(np.array(q))\n",
    "\n",
    "        # Check terminal condition\n",
    "            \n",
    "        data['p'].append(np.array(p_history))\n",
    "        data['qhat'].append(np.array(qhat_history))\n",
    "        data['q'].append(np.array(q_history))\n",
    "\n",
    "    print('Time:',time.time()-t)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 25.895650625228882\n",
      "Time: 46.4497857093811\n",
      "Time: 85.42252373695374\n",
      "Time: 164.1415343284607\n"
     ]
    }
   ],
   "source": [
    "N_trails = 100\n",
    "N_iter = 150\n",
    "FIM_cons_iter = 10\n",
    "\n",
    "q = np.array([6,6])  \n",
    "\n",
    "for N_sen in [5,10,20,40]:\n",
    "\n",
    "# for N_sen in [40]:\n",
    "\n",
    "    data={}\n",
    "\n",
    "    data['Coord.+Consensus Est.'] = main(q,N_trails,N_sen,N_iter,consensus_est=True,coordinate=True,version='v1', FIM_cons_iter = FIM_cons_iter)\n",
    "\n",
    "    with open('CoordConsensusEst-{}Senor-{}FIMConsIter.pkl'.format(N_sen,FIM_cons_iter),'wb') as file:\n",
    "        pkl.dump(data,file)\n",
    "\n",
    "\n",
    "# data['Coordination v3'] = main(N_trails,coordinate=True,version='v3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
