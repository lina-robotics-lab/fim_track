{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook implements the coordinated version of FIM gradient descent, so that the sensors minimizes can adapt their step updates to maximize the global FIM in a distributed fashion.\n",
    "\n",
    "# In particular, we try to find a communication network which shows the importance of coordination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "from matplotlib import style\n",
    "import jax.numpy as jnp\n",
    "from jax import jacfwd, jit,grad\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from Robot import Robot\n",
    "from virtual_sensor import virtual_sensor\n",
    "from utils.DynamicFilters import getDynamicFilter,joint_meas_func\n",
    "from utils.FIMPathPlanning import FIM_descent_path_planning \n",
    "from utils.dLdp import analytic_FIM,analytic_dLdp,analytic_dhdz,analytic_dhdq\n",
    "from utils.regions import CircleExterior\n",
    "from utils.ConsensusEKF import ConsensusEKF\n",
    "from tracking_log import logger\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up F_tilde data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def star(i,q,p):\n",
    "    \"\"\"\n",
    "        Generate a star graph with len(p) nodes, with node 0 being the network center.\n",
    "    \"\"\"\n",
    "    n = len(p)-1\n",
    "    G = nx.star_graph(n)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circulant(i,q,p,prev,post,undirected=False):\n",
    "    \"\"\"\n",
    "        Generate a circulant graph with len(p) nodes, node i connected with [i-prev:i+post],i-prev and i+post included but self-loop eliminated.\n",
    "    \"\"\"\n",
    "    n = len(p)\n",
    "    G = nx.DiGraph()\n",
    "    edges = [(j%n,i) for i in range(n) for j in range(i-prev,i+post+1)]\n",
    "    G.add_edges_from(edges)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    if undirected:\n",
    "        G = G.to_undirected()\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(initial_locs,comm_network_generator,N_iter,C_gain,F_gain,coordinate=False):\n",
    "    \"\"\"\n",
    "    Note: \n",
    "    comm_network_generator(i,qs,ps) is the expected signature of the second argument.\n",
    "\n",
    "        Given the iteration number i, source location qs, sensor location ps,\n",
    "        comm_network_generator return the current communication network G.\n",
    "    \n",
    "    C_main is the gain for ConsensusEKF\n",
    "    \n",
    "    F_gain is the gain for global FIM consensus.\n",
    "    \"\"\"\n",
    "    # Set up mobile sensors and sources\n",
    "    sensor_names = [\"mobile_sensor_{}\".format(i+1) for i in range(len(initial_locs))]\n",
    "    mobile_sensors = [Robot(loc,name) for loc,name in zip(initial_locs,sensor_names)]\n",
    "\n",
    "    src_locs = [[8.,8]]\n",
    "    src_names = [\"source_{}\".format(i+1) for i in range(len(src_locs))]\n",
    "    source = [Robot(loc,name) for loc,name in zip(src_locs,src_names)]\n",
    "\n",
    "    # Set up virtual sensors\n",
    "    C1=-0.3 # Setting C1 as a negative number mitigates the blowing-up effect when the sensors are close to the source.\n",
    "    C0=0\n",
    "    k=1\n",
    "    b=-2\n",
    "    std = 0.1\n",
    "    vs = virtual_sensor(C1,C0,b,k,std)\n",
    "\n",
    "    # Set up location estimator\n",
    "    n_sen = len(mobile_sensors)\n",
    "    n_src = len(source)\n",
    "\n",
    "    C1s=C1*np.ones(n_sen)\n",
    "    C0s = C0*np.ones(n_sen)\n",
    "    ks = k * np.ones(n_sen)\n",
    "    bs = b*np.ones(n_sen)\n",
    "\n",
    "    q_0 = np.random.rand(len(mobile_sensors),2)*10\n",
    "    estimators = [ConsensusEKF(q,C_gain=C_gain) for q in q_0]\n",
    "\n",
    "    # Set up data logger\n",
    "    log = logger(sensor_names,src_names)\n",
    "    log.est_locs_log =dict({\"Est {}\".format(sensor):[] for sensor in sensor_names})\n",
    "    F_est_log = {name:[] for name in sensor_names}\n",
    "    F_est_log['FIM Glob'] = []\n",
    "\n",
    "    \n",
    "    # Assume fixed topology, pre-set the measurement model and waypoint planner(expensive to be created in the main loop)\n",
    "    ps = np.array([r.loc for r in mobile_sensors])\n",
    "    qs = np.array([s.loc for s in source])\n",
    "    G = comm_network_generator(0,qs,ps)\n",
    "   \n",
    "    hs = []\n",
    "    dhdzs = []\n",
    "    dhdqs = []\n",
    "    f_dLdps = []\n",
    "    \n",
    "    for i in G.nodes():\n",
    "        N_i = [i]+list(G[i])     \n",
    "       \n",
    "        C1s_i=C1s[N_i]\n",
    "        C0s_i = C0s[N_i]\n",
    "        ks_i = ks[N_i]\n",
    "        bs_i = bs[N_i]\n",
    "        h=partial(joint_meas_func,C1s_i,C0s_i,ks_i,bs_i)# Freeze the coefficients, the signature becomes h(z,ps)\n",
    "        hs.append(h)\n",
    "        \n",
    "        dhdzs.append(partial(analytic_dhdz,C1s=C1s_i,C0s=C0s_i,ks=ks_i,bs=bs_i))\n",
    "        dhdqs.append(partial(analytic_dhdq,C1s=C1s[i],C0s=C0s[i],ks=ks[i],bs=bs[i]))\n",
    "        \n",
    "        f_dLdps.append(partial(analytic_dLdp,C1s=C1s_i,C0s=C0s_i,ks=ks_i,bs=bs_i))\n",
    "        \n",
    "    \n",
    "    # Create the list of single-term partial FIM's.\n",
    "    def F_single(dh,qhat,ps):\n",
    "        A = dh(qhat,ps)\n",
    "        return A.T.dot(A)\n",
    "    \n",
    "    F = np.array([F_single(dhdqs[i],q_0[i],ps[i:i+1]) for i in range(n_sen)])\n",
    "    \n",
    "    # Create the list local estimate of global FIM.\n",
    "    F_est = np.array([F+1e-8*np.eye(2)  for F in F])\n",
    "   \n",
    "    # Enter main loop\n",
    "    for _ in range(N_iter):\n",
    "\n",
    "        # Measure\n",
    "        ps = np.array([r.loc for r in mobile_sensors])\n",
    "        qs = np.array([s.loc for s in source])\n",
    "        '''The zhats are newly added'''\n",
    "        zhats = np.array([est.z for est in estimators])\n",
    "\n",
    "        y = vs.measurement(qs,ps)\n",
    "\n",
    "        # Set up the current communication network.\n",
    "        G = comm_network_generator(1,qs,ps)\n",
    "        log.comm_network.append(G)\n",
    "\n",
    "        # Record\n",
    "        for s in source:\n",
    "            log.src_locs[s.name].append(s.loc)\n",
    "\n",
    "\n",
    "\n",
    "        # Estimate, plan and move a step for each robot.\n",
    "        for i in G.nodes():\n",
    "            # Get all robots queriable in the comm. network, including i.\n",
    "            # Note: i's place within N_i is always at index 0\n",
    "\n",
    "            \"\"\" The following line gets all the immediate neighbors rather than all ancestors, which is way this Notebook is prefixed with P2P(point to point)\"\"\"\n",
    "\n",
    "            N_i = [i]+list(G[i]) \n",
    "\n",
    "            n_sen = len(N_i)\n",
    "\n",
    "            # Simulate query of information from other robots. \n",
    "            ps_i =ps[N_i]\n",
    "            y_i = y[N_i]\n",
    "            '''The gathering of z_neighbor is newly added'''\n",
    "            z_neighbor = zhats[N_i]\n",
    "            qhat_neighbor = z_neighbor[:,:2]\n",
    "\n",
    "            # Estimate\n",
    "            qhat = estimators[i].update_and_estimate_loc(hs[i],dhdzs[i],y_i,ps_i,z_neighbor)\n",
    "\n",
    "            # Calculate the local FIM estimate.\n",
    "            F_curr = F_single(dhdqs[i],qhat,ps[i:i+1])\n",
    "            \n",
    "#             F_curr = F_single(dhdqs[i],qs,ps[i:i+1])\n",
    "            \n",
    "            F_est[i]=F_est[i]\\\n",
    "                +F_gain*(np.sum(F_est[N_i]-F_est[i],axis=0))\\\n",
    "                +F_curr-F[i]# The consensus driving term.\n",
    "            \n",
    "            F[i]=np.array(F_curr) # Update the single term partial FIM's\n",
    "\n",
    "                    \n",
    "            # Set up waypoint planner\n",
    "            if coordinate:\n",
    "                f_dLdp = partial(f_dLdps[i],FIM=F_est[i])\n",
    "            else:\n",
    "                f_dLdp=f_dLdps[i]\n",
    "\n",
    "            planning_timesteps = 1\n",
    "            if i==0: # The drone, the center of the star, moves fast.\n",
    "                max_linear_speed = 0.22\n",
    "            else:\n",
    "                max_linear_speed = 0.22 # The slowly moving ground vehicle\n",
    "            planning_dt = 1\n",
    "            epsilon = 0.5\n",
    "            # The FIM waypoint planning  \n",
    "            waypoints=FIM_descent_path_planning(f_dLdp,qhat_neighbor,ps_i,n_sen,\\\n",
    "                            planning_timesteps,\\\n",
    "                            max_linear_speed,\\\n",
    "                            planning_dt,\\\n",
    "                            epsilon)\n",
    "            # Note: i's place within N_i is always at index 0\n",
    "            # Move to the 0th waypoint\n",
    "            mobile_sensors[i].update_loc(waypoints[0][0])\n",
    "            m = mobile_sensors[i]\n",
    "\n",
    "            log.sensor_locs[m.name].append(m.loc)\n",
    "            log.est_locs_log[\"Est {}\".format(m.name)].append(qhat)\n",
    "            \n",
    "            F_est_log[m.name].append(np.array(F_est[i]))# Append a deep copy of the estimated FIM\n",
    "            \n",
    "        F_est_log['FIM Glob'].append(analytic_FIM(qs,ps,C1s,C0s,ks,bs)/n_sen)\n",
    "\n",
    "    record=log.export()\n",
    "    record['FIM_est']=F_est_log\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment:1/10\n",
      "Experiment:2/10\n",
      "Experiment:3/10\n",
      "Experiment:4/10\n",
      "Experiment:5/10\n",
      "Experiment:6/10\n",
      "Experiment:7/10\n",
      "Experiment:8/10\n",
      "Experiment:9/10\n",
      "Experiment:10/10\n",
      "Experiment:1/10\n",
      "Experiment:2/10\n",
      "Experiment:3/10\n",
      "Experiment:4/10\n",
      "Experiment:5/10\n",
      "Experiment:6/10\n",
      "Experiment:7/10\n",
      "Experiment:8/10\n",
      "Experiment:9/10\n",
      "Experiment:10/10\n",
      "Experiment:1/10\n",
      "Experiment:2/10\n",
      "Experiment:3/10\n",
      "Experiment:4/10\n",
      "Experiment:5/10\n",
      "Experiment:6/10\n",
      "Experiment:7/10\n",
      "Experiment:8/10\n",
      "Experiment:9/10\n",
      "Experiment:10/10\n"
     ]
    }
   ],
   "source": [
    "n_sensor = 6\n",
    "C_gain = 0.2\n",
    "for F_gain_ratio in [0,0.1,0.2]:\n",
    "    rep_log = []\n",
    "    n_expr = 10\n",
    "    for _ in range(n_expr):\n",
    "        initial_locs = np.random.rand(6,2)*3\n",
    "        print('Experiment:{}/{}'.format(_+1,n_expr))\n",
    "        comm_network=lambda i,q,p:circulant(i,q,p,prev=1,post=2,undirected=True)\n",
    "        F_gain = F_gain_ratio*1\n",
    "        \n",
    "        log = main(initial_locs,comm_network,60,C_gain,F_gain,coordinate=F_gain!=0)\n",
    "        \n",
    "        rep_log.append(log)\n",
    "\n",
    "    filepath = \"CoordDescent-F_gain_ratio{}-v1.pkl\".format(F_gain_ratio)\n",
    "    with open(filepath,'wb') as file:\n",
    "        pkl.dump(rep_log,file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
