{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook further optimize the simulation efficiency by vectorizing the measurement generation & gradient calc and update. Only ConsensusEKF is still performed via a subloop due to its stateful nature, where vectorization is difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Also, we only consider fixed-topology networks in the experiments below.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation, rc\n",
    "\n",
    "import pickle as pkl\n",
    "import networkx as nx\n",
    "from matplotlib import style\n",
    "from functools import partial\n",
    "\n",
    "from utils.dLdp import analytic_dLdp,analytic_dhdz,analytic_dhdq\n",
    "from utils.ConsensusEKF import ConsensusEKF\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up F_tilde data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circulant(i,q,p,prev,post,undirected=False):\n",
    "    \"\"\"\n",
    "        Generate a circulant graph with len(p) nodes, node i connected with [i-prev:i+post],i-prev and i+post included but self-loop eliminated.\n",
    "    \"\"\"\n",
    "    n = len(p)\n",
    "    G = nx.DiGraph()\n",
    "    edges = [(j%n,i) for i in range(n) for j in range(i-prev,i+post+1)]\n",
    "    G.add_edges_from(edges)\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "    if undirected:\n",
    "        G = G.to_undirected()\n",
    "    return G\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_meas_func(C1,C0,k,b,dist):\n",
    "    return k*(dist-C1)**b+C0\n",
    "\n",
    "def joint_meas_func(C1s,C0s,ks,bs,x,ps):\n",
    "\n",
    "    # Casting for the compatibility of jax.numpy\n",
    "\n",
    "    C1=np.array(C1s)\n",
    "    C0=np.array(C0s)\n",
    "    k=np.array(ks)\n",
    "    b=np.array(bs)\n",
    "    p=np.array(ps)\n",
    "\n",
    "    # Keep in mind that x is a vector of [q,q'], thus only the first half of components are observable.    \n",
    "    dists=np.linalg.norm(x[:len(x)//2]-p,axis=1)\n",
    "\n",
    "    return single_meas_func(C1,C0,k,b,dists) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_sen = 6 # Number of sensors.\n",
    "\n",
    "p_0 = np.random.rand(N_sen,2)*3\n",
    "qhat_0 = np.random.rand(N_sen,2)*10\n",
    "q = np.array([6,6])\n",
    "\n",
    "comm_network_generator=lambda i,q,p:circulant(i,q,p,prev=1,post=0,undirected=True)\n",
    "\n",
    "N_iter=100\n",
    "C_gain=0.1\n",
    "coordinate=False\n",
    "\n",
    "# Set up virtual sensors\n",
    "C1=-0.3 # Setting C1 as a negative number mitigates the blowing-up effect when the sensors are close to the source.\n",
    "C0=0\n",
    "k=1\n",
    "b=-2\n",
    "noise_std = 0.01\n",
    "minimum_sensing_reading=1e-5\n",
    "\n",
    "# Data containers\n",
    "p = np.array(p_0) # Sensor Positins\n",
    "qhat = np.array(qhat_0)\n",
    "\n",
    "\n",
    "\n",
    "# Create the list of single-term partial FIM's.\n",
    "def F_single(dh,qhat,ps):\n",
    "    A = dh(qhat,ps)\n",
    "    return A.T.dot(A)\n",
    "\n",
    "def joint_F_single(qhat,ps): # Verified to be correct.\n",
    "    # The vectorized version of F_single.\n",
    "    # The output shape is (N_sensor, q_dim, q_dim).\n",
    "    # Where output[i]=F_single(dh,qhat,ps[i])\n",
    "    A = analytic_dhdq(qhat,ps,C1s=C1,C0s=C0,ks=k,bs=b)\n",
    "    return A[:,np.newaxis,:]*A[:,:,np.newaxis]\n",
    "\n",
    "\n",
    "# Create the list local estimate of global FIM.\n",
    "F_0 = joint_F_single(qhat,p)\n",
    "F = np.array(F_0)\n",
    "F_est = F+1e-8*np.eye(2) # Adding a small I to ensure invertibility\n",
    "\n",
    "# Create the communication network and consensus weight matrix.\n",
    "G = comm_network_generator(0,q,p)\n",
    "estimators = [ConsensusEKF(q_0,C_gain=C_gain) for q_0 in qhat_0]\n",
    "A = np.array(nx.adj_matrix(G).todense().astype(float))\n",
    "A +=np.eye(len(A))\n",
    "\n",
    "W = A/np.sum(A,axis=1) # The weight matrix required by parallel two-pass algorithm.\n",
    "\n",
    "# The initialization of local measurement functions and the derivative functions. \n",
    "# This is not very pretty. But is required by Consensus EKF.\n",
    "hs = []\n",
    "dhdzs = []\n",
    "dhdqs = []\n",
    "C1s=C1*np.ones(N_sen)\n",
    "C0s = C0*np.ones(N_sen)\n",
    "ks = k * np.ones(N_sen)\n",
    "bs = b*np.ones(N_sen)\n",
    "\n",
    "\n",
    "d = np.zeros(N_sen)\n",
    "for i in G.nodes():  \n",
    "    N_i = [i]+list(G[i])     \n",
    "    C1s_i=C1s[N_i]\n",
    "    C0s_i = C0s[N_i]\n",
    "    ks_i = ks[N_i]\n",
    "    bs_i = bs[N_i]\n",
    "    hs.append(partial(joint_meas_func,C1s_i,C0s_i,ks_i,bs_i))# Freeze the coefficients, the signature becomes h(z,ps))\n",
    "    dhdzs.append(partial(analytic_dhdz,C1s=C1s_i,C0s=C0s_i,ks=ks_i,bs=bs_i))\n",
    "    dhdqs.append(partial(analytic_dhdq,C1s=C1s_i,C0s=C0s_i,ks=ks_i,bs=bs_i))\n",
    "    d[i]=len(N_i)\n",
    "\n",
    "# Variables for parallel two-pass algorithm.\n",
    "inv_d = 1/d\n",
    "w_F_est = F_est/d[:,np.newaxis,np.newaxis]\n",
    "    \n",
    "import time\n",
    "\n",
    "t=time.time()\n",
    "\n",
    "\n",
    "\n",
    "# Enter main loop\n",
    "for _ in range(N_iter):\n",
    "    # Measure\n",
    "    r = np.linalg.norm(q-p,axis=1)\n",
    "    y = k* ((r-C1)**b)+C0 + np.random.randn(N_sen)*noise_std\n",
    "    y[y<=0]=minimum_sensing_reading # We don't want y to be zero or negative.\n",
    "    \n",
    "    \n",
    "    # Estimate\n",
    "    zhats = np.array([est.z for est in estimators])\n",
    "    for i in G.nodes():\n",
    "        N_i = [i]+list(G[i]) \n",
    "        # Estimate\n",
    "        qhat[i,:]=estimators[i].update_and_estimate_loc(hs[i],dhdzs[i],y[N_i],p[N_i],zhats[N_i])\n",
    "    #print(np.linalg.norm(qhat-q))\n",
    "    \n",
    "    # Partial FIM Calculation\n",
    "    for _ in range(5):\n",
    "        new_F = joint_F_single(qhat,p)\n",
    "        dF = new_F-F\n",
    "        F=new_F\n",
    "\n",
    "        # FIM Consensus using parallel two-pass algorithm\n",
    "        inv_d = W.dot(inv_d)\n",
    "        w_F_est = (w_F_est.T.dot(W)).T + dF/d[:,np.newaxis,np.newaxis]\n",
    "        F_est = w_F_est/inv_d[:,np.newaxis,np.newaxis]   \n",
    "    \n",
    "    # Gradient update\n",
    "    \n",
    "print('Time:',time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[3.47068727e-05 4.14680612e-05]\n",
      "  [4.14680612e-05 5.04195518e-05]]\n",
      "\n",
      " [[3.61737056e-05 4.21559486e-05]\n",
      "  [4.21559486e-05 5.07791037e-05]]\n",
      "\n",
      " [[3.38298239e-05 4.04855950e-05]\n",
      "  [4.04855950e-05 5.02448466e-05]]\n",
      "\n",
      " [[3.37645436e-05 3.75336216e-05]\n",
      "  [3.75336216e-05 4.38092207e-05]]\n",
      "\n",
      " [[3.22977107e-05 3.68457342e-05]\n",
      "  [3.68457342e-05 4.34496688e-05]]\n",
      "\n",
      " [[3.46415925e-05 3.85160879e-05]\n",
      "  [3.85160879e-05 4.39839259e-05]]]\n"
     ]
    }
   ],
   "source": [
    "print(F_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.42257082e-05 3.95008414e-05]\n",
      " [3.95008414e-05 4.71043863e-05]]\n"
     ]
    }
   ],
   "source": [
    "ave_F = np.average(joint_F_single(qhat,p),axis=0)\n",
    "\n",
    "print(ave_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.91598886e-05 3.41824632e-05]\n",
      " [3.41824632e-05 4.06588571e-05]]\n"
     ]
    }
   ],
   "source": [
    "true_F=np.average(joint_F_single(q,p),axis=0)\n",
    "\n",
    "print(true_F)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
